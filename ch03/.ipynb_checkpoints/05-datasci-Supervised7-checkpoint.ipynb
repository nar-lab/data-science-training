{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED ANALYTICS 2018\n",
    "_Author: Ali Ã‡abukel_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "- Decision Trees can be used both of classification and regression tasks, also feature selection.\n",
    "- It has a hierarchical tree structure which a user can read the results easily. Tree structure has the following objects:\n",
    "    + Root node: the starting node of tree\n",
    "    + Split nodes: the nodes are between root and leaf/terminal nodes. Split nodes keep the significant input variable and cut-off values\n",
    "    + Leaf nodes: The terminal nodes of tree. You can make decision using terminals\n",
    "- It can be called as recursive partioning and some DT algorithms are ID3, J48, C4.5, C5.0 and C&R.\n",
    "- Decision trees tend to overfitting problem and some advanaced tree algorithms are developed for this reason:\n",
    "    + Bagging trees: Bootstrap aggregating, RandomForests (Ensemble tree)\n",
    "    + Boosted tress: Adaboost, GBM, LightGBM, xgboost... (sequential, steepest process stochastic gradient descent)\n",
    "    + The objective of boosting is a find strong predictor using weak learner, the method is better than random guess\n",
    "    + Also pruning tree, decreasing tree depth are other techniques to stop overfitting \n",
    "- Splitting criteria for tree: Entropy based Information Gain, Gini, Chi-square\n",
    "- How to interpret the results/metrics:\n",
    "    + Support is the #observations in the total population for any node\n",
    "    + Confidence is the #positive class rate in the #total cases in a node\n",
    "- The initial settings of decision trees:\n",
    "    + Number of tree depth, Splitting criteria (gain, gini),  Mininum percent in a split, Mininum percent in a node (You need to decide the final class if the terminal has sufficient observations)\n",
    "    \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Trees](../img/ch03/supervised6/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Recursive Partitioning](../img/ch03/supervised6/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Tree Classification](../img/ch03/supervised6/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Forests, Ensemble Baggin Trees](../img/ch03/supervised6/4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eXtreme Gradient Boosting](../img/ch03/supervised6/5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Strong Predictor from Weak Learners](../img/ch03/supervised6/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Adaboost](../img/ch03/supervised6/7.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
